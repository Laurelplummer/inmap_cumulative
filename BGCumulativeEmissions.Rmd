---
title: "BG Cumulative Emissions"
author: "Laurel Plummer"
date: "6/25/2021"
output: html_document
---
#Setup
```{r setup, include=FALSE}
#Install and update required packages 
if(!require(pacman)){install.packages("pacman");
  library(pacman)}
p_load(knitr, readxl, dplyr, tidyr, tidyverse, ggplot2, janitor, scales, wesanderson, sf, naniar)

knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "U:/CEERB/CHEIS/AB32_Analysis/")

#Time stamp of date exported
export_date <- Sys.Date()

outputPath <- "Analysis_Cap_and_Trade/R_output/bg_cumulative/" #Directory where you want your results saved. Make sure there's a slash at the end
```

#Read in stack data and convert each to sf object/shapefile
##2012 Stack Data
```{r}
#Read in csv of 2012 Stack Data
stk2012 <-read.csv(file = "U:/CEERB/CHEIS/AB32_Analysis/Data/CARB_CEIDARS_StackEmissionsData/CEIDARS_2020_12_17/CEIDARS_Clean/stk12_FULL_0308.csv") %>% #8226 obs
  #filter out NAs
  filter(!is.na(SLON_NAD83)) #6793 obs

#Data cleaning for 2012 stack emissions data
stk2012_clean <- stk2012 %>% 
    #Data cleaning for stack height (STKHT): Change NAs and zeros to 121.4 ft for non-ground stacks (ground - STK = 9999)
  rename(STKHT_original = STKHT) %>% #change STKHT->STKHT_original to save raw data
  mutate(STKHT = ifelse(STKHT_original == 0, 121.4,
                #If original stack height is NA and stack id is NOT 9999, then 121.4
                  ifelse(is.na(STKHT_original) & STK != 9999, 121.4, 
                      ifelse(is.na(STKHT_original) & STK == 9999, 0,
                          STKHT_original)))) %>%
  #Data cleaning: Convert from feet to meters by dividing by 3.2808 before separating to height layers
  mutate(STKHT = STKHT/3.2808) %>%
  #Data cleaning: Create new column with height layer – Layer1, Layer2, Layer3, Layer2_3. OR divide into 4 separate data frames. Layers (L1: <57m, L2: >=57 and <140m, L3: >=760m, in between L2 and L3: >=140 and <760 m)
  mutate(HTLAYER = ifelse(STKHT < 57, "L1", #0-57m
                          ifelse(STKHT >=57 & STKHT <140, "L2",#57-140 meters, 
                                 ifelse(STKHT >=760, "L3", #and above 760 meters
                                        ifelse(STKHT >=140 & STKHT <760, "L2_3",
                                               NA))))) %>%
  select(arbid_facid, STK, STKNAME, STKHT, HTLAYER, SLAT_NAD83, SLON_NAD83, PM2.5:NH3)

#Convert to sf
sf_stk2012 <- st_as_sf(stk2012_clean, coords = c("SLAT_NAD83", "SLON_NAD83"), crs = 3310)

#Remove old files to save space
rm(stk2012)
rm(stk2012_clean)

plot(sf_stk2012)

```
 
##2017 Stack Data
```{r}
#Read in csv of 2017 Stack Data 
stk2017 <-read.csv(file = "U:/CEERB/CHEIS/AB32_Analysis/Data/CARB_CEIDARS_StackEmissionsData/CEIDARS_2020_12_17/CEIDARS_Clean/stk17_FULL_0308.csv") %>% #7754 obs
  #filter out NAs
  filter(!is.na(SLON_NAD83)) #6326 obs

#Data cleaning (check ISRM function file on github)
  #1. Change NAs and zero’s for height to 121.4 feet.  
stk2017_clean<- stk2017 %>% 
  rename(STKHT_original = STKHT) %>%
  mutate(STKHT = ifelse(STKHT_original == 0, 121.4,
                  ifelse(is.na(STKHT_original) & STK != 9999, 121.4,
                      ifelse(is.na(STKHT_original) & STK == 9999, 0,
                          STKHT_original)))) %>%
  #Convert from feet to meters by dividing by 3.2808 before separating to height layers
  mutate(STKHT = STKHT/3.2808) %>%
  #2. Create new column with height layer – Layer1, Layer2, Layer3, Layer2_3. OR divide into 4 separate data frames. Layers (L1: <57m, L2: >=57 and <140m, L3: >=760m, in between L2 and L3: >=140 and <760 m)
  mutate(HTLAYER = ifelse(STKHT < 57, "L1", #0-57m
                          ifelse(STKHT >=57 & STKHT <140, "L2",#57-140 meters, 
                                 ifelse(STKHT >=760, "L3", #and above 760 meters
                                        ifelse(STKHT >=140 & STKHT <760, "L2_3",
                                               NA))))) 

#Convert to sf
sf_stk2017 <- st_as_sf(stk2017_clean, coords = c("SLAT_NAD83", "SLON_NAD83"), crs = 3310)

rm(stk2017)
rm(stk2017_clean)
```
 
#Read in block group (bg) mean centers of population from txt file available through the Census online here: https://www.census.gov/geographies/reference-files/2010/geo/2010-centers-population.html
```{r}
bg_popwt <- read.delim("Data/US_Census/Spatial_Data/CenPop2010_Mean_BG06.txt", header = TRUE, sep = ",", dec = ".", colClasses = c(rep("character", 5), "numeric", "numeric")) %>%
  clean_names() %>%
  #Create a new column 'census tract GEOID' for bg mean center of pop that is based on the three variables in the BG_popwt file. This will be used for joining later
    mutate(geoid_bg = paste(statefp, countyfp, tractce, blkgrpce, sep="")) %>%
    mutate(geoid = paste(statefp, countyfp, tractce, sep="")) %>%
    mutate(geoid_bg = as.numeric(geoid_bg), geoid = as.numeric(geoid)) %>%
  select(geoid_bg, everything())

#Convert to sf
sf_bg_popwt <- st_as_sf(bg_popwt, coords = c("latitude", "longitude"), crs = 3310)

#Remove the csv of block group points  
rm(bg_popwt)
```

#Create buffer polygons for 2.5 miles Block Group Population Weighted Centroids which will represent the block groups
```{r}
sf_bg_2.5miles <- st_buffer(sf_bg_popwt, 4023.36) #4023.36 is 2.5 miles in meters

#Remove the sf of block group points  
rm(sf_bg_popwt)
```

 
 
```{r}
# Function to separate emissions by height into the 3 layers of the ISRM and emissions in between layers 2 and 3
emisByHeight <- function(sf_stk2017){
  
  L1 <- sf_stk2017 %>%
    filter(STKHT < 57)
  
  L2 <- sf_stk2017 %>%
    filter(STKHT >= 57 & STKHT < 140)
  
  L3 <- sf_stk2017 %>%
    filter(STKHT >=760)
  
  L2_3 <- sf_stk2017 %>%
    filter(STKHT >= 140 & STKHT < 760)
  
  emisList <- list(L1,L2,L3,L2_3)
  
  return(emisList)
  
}
```
 
```{r}
# Specify conversion multiplier. This is the multiplier to convert tons/year to ug/s
conv_mult = (2000 * 453.592 * 10**6) / (525600 * 60)
```

 
```{r}
# Function to sum emissions per block group buffer, join with entire InMAP grid, fill in missing values, and convert units to micrograms/second
emisPerbuffer <- function(df, conv_mult){
  
  # Create dataframe of zero's to hold receptor conc and source contribution by cell
  mat <- matrix(0, ncol = 12, nrow = 21705)
  colnames(mat) <- c("PrimaryPM25_rec","SOA_rec","pNH4_rec","pNO3_rec","pSO4_rec","PrimaryPM25_src","SOA_src","pNH4_src","pNO3_src","pSO4_src","TotPM_rec","TotPM_src")
  
  
  if(any(df$STKHT >= 140 & df$STKHT < 760)){
    df %<>%
      group_by(geoid_bg, STKHT) %>%
      summarise(PM2_5 = sum(PM2_5),
                NOx = sum(NOx),
                SOx = sum(SOx),
                VOC = sum(VOC),
                NH3 = sum(NH3)) %>%
      ungroup()
    
  } else {
    df %<>%
      group_by(geoid_bg) %>%
      summarise(PM2_5 = sum(PM2_5),
                NOx = sum(NOx),
                SOx = sum(SOx),
                VOC = sum(VOC),
                NH3 = sum(NH3)) %>%
      ungroup()
  }
  
  df %<>%
    st_set_geometry(NULL) %>%
    right_join(bg_buffer, by = "geoid_bg", all = TRUE) %>%
    mutate(PM2_5 = ifelse(is.na(PM2_5), 0, PM2_5 * conv_mult)) %>%
    mutate(NOx = ifelse(is.na(NOx), 0, NOx * conv_mult)) %>%
    mutate(SOx = ifelse(is.na(SOx), 0, SOx * conv_mult)) %>%
    mutate(VOC = ifelse(is.na(VOC), 0, VOC * conv_mult)) %>%
    mutate(NH3 = ifelse(is.na(NH3), 0, NH3 * conv_mult)) %>%
    select(-geometry) %>%
    arrange(geoid_bg) %>%
    cbind(mat) %>%
    as.matrix()
  
  return(df)
}
```
 
 
```{r}
# Join wrapper function
# Spatial join of emissions to block group buffers. Then run through the emisByHeight(), ?emisPerGrid(), and ?getSRconc() functions.
# Split results from ground-level, stack, and total emissions.
# Join with InMAP grid again to get spatial information, change colname to be <10 char, and return as a list of 3 sf objects.


joinWrapper <- function(emis,bg_buffer,conv_mult){
  #isrm <- nc_open(isrmPath)
  
  # Change CRS if emis does not have the same crs as inmapGrid
  if(st_crs(emis) != st_crs(bg_buffer)){
    emis %<>%
      st_transform(st_crs(bg_buffer))
  }
  
  stopifnot(st_crs(emis) == st_crs(bg_buffer))
  
  emisMat <- st_join(emis,bg_buffer) %>%
    emisByHeight() %>%
    lapply(. %>% (function (x) emisPerbuffer(x,conv_mult)))
  
  results <- imap(emisMat, function(x,y) getSRconc(emis = x, idx = y, isrm = isrm, isrmPol = isrmPol, emisPol = emisPol))
  
}
  #nc_close(isrm)
```

```{r}

### USER INPUT - Set run options ##############################################

# Specify file paths
#inmapGridPath <- "U:/CEERB/CHEIS/AB32_Analysis/Modeling/InMAP/Chambliss_Deliverables_v1_09182020/Data Deliverables/InMAP_shapefile/InMAP_gridCells.shp"
#isrmPath <- "C:/Users/AChen/OneDrive - California OEHHA/InMAP/RawData/ca_isrm.nc4"
#emisPath <- "U:/CEERB/CHEIS/AB32_Analysis/Data/CARB_CEIDARS_StackEmissionsData/CEIDARS_2020_12_17/CEIDARS_Clean/stk17_FILTER_0308/stk17_FILTER_inmap.shp"
#outputPath <- "U:/CEERB/CHEIS/AB32_Analysis/Analysis_Cap_and_Trade/R_output/ISRM/stk17_FILTER/" #Directory where you want your results saved. Make sure there's a slash at the end


# Specify if you want results for each individual sector (TRUE) or in aggregate (FALSE). For analysis of emissions in aggregate, concentrations from ground-level, stack, and total emissions will be exported separately. For sector-level results, only the concentrations from total emissions for that sector will be exported.
sectorDetail <- FALSE

# Specify conversion multiplier. This is the multiplier to convert tons/year to ug/s
conv_mult = (2000 * 453.592 * 10**6) / (525600 * 60)

# Specify names of pollutants in emissions data and matching names in ISRM
emisPol <- c("PM2.5","VOC","NH3","NOx","SOx")
#isrmPol <- c("PrimaryPM25","SOA","pNH4","pNO3","pSO4")

### END OF USER INPUT #########################################################
 # Read in data

emis <- sf_stk2012
bg_buffer <- sf_bg_2.5miles

# Run through ISRM functions and export shapefiles
if(sectorDetail == FALSE){
  results <- joinWrapper(emis,bg_buffer,conv_mult)
  
  # Export individual shapefiles for concentrations due to ground-level,stack, and total emissions
  for(i in 1:length(results)){
    st_write(results[[i]], paste0(outputPath,basename(outputPath),"_",names(results)[i],".shp"), driver = "ESRI shapefile")
  }
} else {
  # Split emissions by sector
  emisBySector <- split(emis, f = emis$sector)
  
  # Run ISRM wrapper function for each sector's set of emissions
  sectorResults <- lapply(emisBySector, function(x) isrmWrapper(emis = x, inmapGrid,conv_mult,isrmPath))
  
  # Get concentrations from total emissions for each sector
  sectorResultsTot <- lapply(sectorResults, function(x) return(x$total))
  
  # Add sector name as a new column
  sectorResultsTot <- imap(sectorResultsTot, function(x,y) addSectorName(emis = x, idx = y))
  
  # Export shapefiles for each sector
  for(i in 1:length(sectorResultsTot)){
    sectors <- names(sectorResultsTot)
    
    # remove spaces in sector names
    sectors <- gsub("[[:space:]]","",sectors)
    
    st_write(sectorResultsTot[[i]], paste0(outputPath,basename(outputPath),"_",sectors[i],"_total.shp"), driver = "ESRI shapefile")
  }
  
}

```





#Read in US Census Block Group Polygon Boundaries https://cengel.github.io/R-spatial/spatialops.html
```{r}
BG_polygon_main <- st_read("U:/CEERB/CHEIS/AB32_Analysis/Data/US_Census/Spatial_Data/tl_2010_06_bg10/tl_2010_06_bg10.shp") 

sf_BG_polygon <- BG_polygon_main %>%
  select(GEOID10, everything()) %>%
  mutate(GEOID10 = as.numeric(GEOID10)) %>%
  rename(geoid_bg = GEOID10)
```


#Join ACS and Quartile Data with Block Group Mean Centers of Population
```{r}

#2. CalEnviroScreen 4 (Draft) Data with Quartiles added (Created here U:\CEERB\CHEIS\AB32_Analysis\Analysis_Cap_and_Trade\Method\OddsRatio --2_Odds Ratio Calculations)
datCES4_wqtls <- read.csv("U:/CEERB/CHEIS/AB32_Analysis/Analysis_Cap_and_Trade/R_output/datCES4_wqtls_2021-06-28.csv")%>%
  rename(geoid = Tract)

#3. ACS block group data 2014-2018 5 year estimates
  #Output from "U:/CEERB/CHEIS/AB32_Analysis/Data/Cap_and_Trade_Analysis/R Scripts/6_Population_ACS.R"
  #This is the block group file created from ACS API script for block group data 14-18
  #We are not using the spatial file because we are just joining the data to the location of the centroids
acs_bg <- read.csv("U:/CEERB/CHEIS/AB32_Analysis/Data/US_Census/Population_Data/BG_ACS_data_14_18_2021-06-28.csv") %>%
  #Change the variable name to reflect that this includes the block group id
  rename(geoid_bg = GEOID) 
```

#Join BG with CES and ACS
```{r}
#Assign each block group centroid the CES percentile and quartile scores, then with the block group acs variables
BG_CES4_ACS <- BG_popwt %>%
  dplyr::select(geoid, everything()) %>%
  #remove the pop column because this is associated with the 2010 census, and we will use the 2018 census info
  dplyr::select(-population) %>%
  #Join with CES
  left_join(datCES4_wqtls[, c("geoid", "pctl_CES", "qtl_CES")], by = c("geoid")) %>%
  #Join with ACS by GEOID_BG
  dplyr::select(geoid_bg, everything()) %>%
  left_join(acs_bg, by = c("geoid_bg")) %>%
  #Filter out the block groups with no population 
  #Block groups coded as 0 are bodies of water, so we are removing these
  filter(blkgrpce != 0) %>% #23212 to 23190 - remove 22 block groups
  #Remove the block groups with no population as of the 2017 census (TO DO: Update to 2018 census)
  filter(pop_total > 0) #23190 to 23139 - remove 51 block groups
```

##Export csv of BG centroids with CES and ACS joined
```{r}
#write.csv(BG_CES4_ACS, paste("Analysis_Cap_and_Trade/R_output/BG_CES4_ACS_", export_date, ".csv", sep = ""), row.names = FALSE) 
```




#Some draft code for plotting
https://ggplot2.tidyverse.org/reference/ggsf.html
```{r}
#check the class before mapping to make sure its sf and didn't convert back to a df
#comment out each one to see if they show up individually
fig <- ggplot() +
  geom_sf(data = sf_BGbuffer2.5miles,fill = NA) +
  geom_sf(data = sf_stk2017, fill = NA) +
  #coord_sf(xlim = c(-1875000,-1864000), ylim = c(-613000,-598000)) +
  theme(axis.text.x = element_text(angle = 45, hjust=1))
fig

ggsave(file = "U:/CEERB/AB617_Shared/Output/Figures/InMAPgrid_Portside.pdf",plot = fig,width = 6, height = 4.5)
```





#OLD CODE
```{r}

#Export shapefile
BG_popwt$long <- as.numeric(BG_popwt$long)
BG_popwt$lat <- as.numeric(BG_popwt$lat)

BG_popwt_spatial <- SpatialPointsDataFrame(coords = BG_popwt[,c("long", "lat")], data = BG_popwt, proj4string = CRS("+proj=longlat +datum=NAD83"))
#shp_dsn <- paste("C:/Users/loneal/Desktop/BG_PopCent_DAC_ACS_spatial_", export_date, sep = "") #update with different desktop when someone else runs
shp_dsn <- paste("C:/Users/lplummer/Desktop/BG_PopCent_DAC_ACS_spatial_", export_date, sep = "")
layer_name <- paste("BG_PopCent_DAC_ACS_spatial_", export_date, sep = "")
writeOGR(BG_popwt_spatial, dsn=shp_dsn, layer=layer_name, driver="ESRI Shapefile")

#OPTIONAL: Census Tract process ------------------------------------------------------------------------------------------------------------------------------------------------------
CT_popwt <-  read.delim("Census/CenPop2010_Mean_TR06.txt", header = TRUE, sep = ",", dec = ".", colClasses = "character")

acs_ct <- read.csv("Population_Data/CT_ACS_data_2019-05-31.csv", colClasses = "character")
#Turn all of the numbers into the numeric format, but keep GEOID as a character
acs_ct[, 3:39] <- sapply(acs_ct[, 3:39], as.numeric)

#CT: Label mean pop centers as DACs ----------------------------------------------------------------------------------------------------------------------------------------------------
#Create census tract GEOID for CT mean center of pop
CT_popwt$GEOID <- paste(CT_popwt$STATEFP, CT_popwt$COUNTYFP, CT_popwt$TRACTCE, sep="")
CT_popwt$GEOID_ct <- substr(CT_popwt$GEOID, 2, 11) #purposely cut off the leading zero for this GEOID_ct because the CES GEOIDs do not have the leading zero

#Create census tract GEOID dataframe for DACs
dac_geoid <- data.frame(dacs$`Census Tract`)
dac_geoid <- dac_geoid %>% 
  rename(GEOID_ct = dacs..Census.Tract.)
dac_geoid$GEOID_ct <- as.character(dac_geoid$GEOID_ct)
dac_geoid$DAC <- 1

#The centroids in DAC census tracts have DAC = 1
CT_popwt <- left_join(CT_popwt, dac_geoid, "GEOID_ct")

#DAC should be 0 for those centroids not in DAC census tracts
CT_popwt$DAC <- ifelse(is.na(CT_popwt$DAC), 0, 1)

#Clean out unnecessary columns
CT_popwt <- subset(CT_popwt, select = -c(POPULATION, GEOID_ct)) #remove the pop column because this is associated with the 2010 census, and we will use the 2017 census info

#CT: Join the centroids with the ACS data -------------------------------------------------------------------------------------------------------------------------------------------

CT_popwt <- left_join(CT_popwt, acs_ct, "GEOID")

#Rename for easier GIS use
CT_popwt <- CT_popwt %>% 
  rename(lat = LATITUDE) %>%
  rename(long = LONGITUDE)

#CT: Filter out the block groups with no population ------------------------------------------------------------------------------------------------------------------------------

#Block groups coded as 0 are bodies of water, so we are removing these for block groups, but not applicable for CT

#Remove the census tracts with no population as of the 2017 census
CT_popwt <- subset(CT_popwt, pop_total > 0) #8057 to 8011 - remove 46

#CT: Export -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
export_date <- Sys.Date()

#Updated CT csv
export_CT_path <- paste("R_output/CT_PopCent_DAC_ACS_",export_date,".csv", sep = "")
write.csv(CT_popwt, file=export_CT_path, row.names=FALSE)

#Export shapefile
CT_popwt$long <- as.numeric(CT_popwt$long)
CT_popwt$lat <- as.numeric(CT_popwt$lat)

CT_popwt_spatial <- SpatialPointsDataFrame(coords = CT_popwt[,c("long", "lat")], data = CT_popwt, proj4string = CRS("+proj=longlat +datum=NAD83"))
shp_dsn <- paste("C:/Users/loneal/Desktop/CT_PopCent_DAC_ACS_spatial_", export_date, sep = "")
layer_name <- paste("CT_PopCent_DAC_ACS_spatial_", export_date, sep = "")
writeOGR(CT_popwt_spatial, dsn=shp_dsn, layer=layer_name, driver="ESRI Shapefile")
```


#Spatial post processing 
```{r}
#### Analysis of Total Emissions Near a Block Group
#Built by: Lauren O'Neal and Laurel Plummer, Last updated on: LP 10/24/19 and LO 9/23/2019

# Libraries ----

if(!require(pacman)){install.packages("pacman");
  library(pacman)}
p_load(dplyr, tidyr, ggplot2, RColorBrewer, tidyverse, writexl, readxl, broom)


# Set up and read in the data --------------------------------------------------------------------------------------------------------------------------------------------
###File path location for data inputs and outputs
setwd("U:/CEERB/CHEIS/AB32_Analysis/Data/Cap_and_Trade_Analysis") 

bg_data <- read_excel("GIS_output/BGplusEmissions_20191024.xlsx") %>%  #10/24 version includes corrected version of toxics
  select(GEOID, DAC, rac_ttl:urb_CT_, include, loc_GHG, loc_CPl, loc_typ, year, pre_pst, sumGHG:nh3) %>% 
  #LO 9/23/19 added demographics and sumGHG, loc_CoPol to loc_CPl, loc_type to loc_typ, pre_post to pre_pst
  #LO 9/9/19 added DAC to above select and removed DAC_2_5 - DAC is about the BG whereas the DAC_2_5 is about the facility
  #ex: a BG that is not a DAC may have a facility nearby that is also near a DAC, so DAC_2_5 could be "Yes" even if the BG in question isn't a DAC - this is confusing/misleading
  filter(include == "yes") %>%
  #Decision point - filter for facilties with co-located emissions data 
  #filter(loc_CPl == 1) #LO 9/23/19 loc_CoPol to loc_CPl
  filter(loc_CPl == 1 & loc_GHG == 1) #filter for only facilities with co-located data 

bg_data_sum <- bg_data %>% 
  group_by(GEOID, year) %>% 
  summarize_at(vars(tog:nh3), sum, na.rm = TRUE) %>% #LO 9/9/19 added vars() around tog:nh3 because "Error in check_dot_cols(.vars, .cols) : object 'tog' not found"
  left_join(unique(select(bg_data, c(GEOID,year,DAC,pre_pst))), by = c('GEOID', 'year')) #LO 9/9 added this line to add back the columns lost in summarize, 9/23/19 pre_post to pre_pst
#calculate the annual emissions for all facilities within 2.5 miles of BG center

#bg_data_sum$DAC_2_5 <- factor(bg_data_sum$DAC_2_5, levels = c("No","Yes")) # LO 9/9 removed, see DAC_2_5 explanation above
bg_data_sum$DAC[bg_data_sum$DAC == 1] <- "Yes" #changing DAC column from 0/1 to yes/no
bg_data_sum$DAC[bg_data_sum$DAC == 0] <- "No"
bg_data_sum$DAC <- factor(bg_data_sum$DAC, levels = c("No","Yes"))
bg_data_sum$pre_pst <- factor(bg_data_sum$pre_pst, levels = c("pre","post")) #LO 9/23/19 pre_post to pre_pst


#example workflow -- 
#summary tables of pm emissions before/after cap and trade in communities from all facilities within 2.5 miles from pop cent of BG
options(scipen = 999)
BG_DAC_prepost <- bg_data_sum %>%
  group_by(GEOID, DAC, pre_pst) %>% #LO 9/9, DAC_2_5 to DAC, 9/23/19 pre_post to pre_pst
  #summarize(mean_pm = mean(annual_pm)) %>% #LO 9/9, replaced with line below
  summarize_at(vars(pm), sum, na.rm = TRUE) %>%
  mutate(logpm = log(1+pm)) #LO 9/9, mean_pm to pm
  
hist(BG_DAC_prepost$pm) #LO 9/9, replaced mean_pm with pm
hist(BG_DAC_prepost$logpm)

mod <- tidy(lm(logpm ~ DAC* pre_pst, data = BG_DAC_prepost)) #LO 9/9, DAC_2_5 to DAC, 9/23/19 pre_post to pre_pst

DAC_prepost <- bg_data_sum %>%
  group_by(DAC, pre_pst) %>% #LO 9/9, DAC_2_5 to DAC, 9/23/19 pre_post to pre_pst
  #summarize(mean_pm = mean(annual_pm)) #LO 9/9, replaced with line below
  summarize_at(vars(pm), sum, na.rm = TRUE)

plot <- ggplot(data = DAC_prepost, aes(x = DAC, y = pm, fill = pre_pst)) + #LO 9/9, DAC_2_5 to DAC, mean_pm to pm, 9/23/19 pre_post to pre_pst
  geom_bar(stat = "identity", position=position_dodge(.9)) +
  theme_bw() + theme(legend.position = "right") +  
  labs(y = "Mean PM Emissions", x = element_blank()) +  
  scale_fill_manual(values = c("gray", "black"))
plot

#modeling pm emissions before/after cap and trade with demographic predictors, LO added 9/23/19
#DAC predictive of higher pm AFTER cap and trade than before
BG_DAC_pre <- BG_DAC_prepost %>%
  filter(pre_pst == "pre") %>%
  left_join(unique(select(bg_data, c(GEOID,rac_ttl:urb_CT_))), by = c('GEOID'))

m1 <- lm(pm ~ DAC + n_wht_p + NHS_pcl + pov_pcl + pp_dns_ + snsAg_p, data = BG_DAC_pre)
summary(m1)

m2 <- lm(pm ~ DAC, data = BG_DAC_pre)
summary(m2)

BG_DAC_post <- BG_DAC_prepost %>%
  filter(pre_pst == "post") %>%
  left_join(unique(select(bg_data, c(GEOID,rac_ttl:urb_CT_))), by = c('GEOID'))

m3 <- lm(pm ~ DAC + n_wht_p + NHS_pcl + pp_dns_ + snsAg_p, data = BG_DAC_post)
summary(m3)

m4 <- lm(pm ~ DAC, data = BG_DAC_post)
summary(m4)

#modeling nox emissions before/after cap and trade with demographic predictors, LO added 9/23/19
#DAC predictive of higher nox BEFORE cap and trade than after
BG_DAC_prepost_nox <- bg_data_sum %>%
  group_by(GEOID, DAC, pre_pst) %>% 
  summarize_at(vars(nox), sum, na.rm = TRUE) %>%
  mutate(logNox = log(1+nox)) 

BG_DAC_pre_nox <- BG_DAC_prepost_nox %>%
  filter(pre_pst == "pre") %>%
  left_join(unique(select(bg_data, c(GEOID,rac_ttl:urb_CT_))), by = c('GEOID'))

m1 <- lm(nox ~ DAC + n_wht_p + NHS_pcl + pov_pcl + pp_dns_ + snsAg_p, data = BG_DAC_pre_nox)
summary(m1)

m2 <- lm(nox ~ DAC, data = BG_DAC_pre_nox)
summary(m2)

BG_DAC_post_nox <- BG_DAC_prepost_nox %>%
  filter(pre_pst == "post") %>%
  left_join(unique(select(bg_data, c(GEOID,rac_ttl:urb_CT_))), by = c('GEOID'))

m3 <- lm(nox ~ DAC + n_wht_p + NHS_pcl + pp_dns_ + snsAg_p, data = BG_DAC_post_nox)
summary(m3)

m4 <- lm(nox ~ DAC, data = BG_DAC_post_nox)
summary(m4)


```


